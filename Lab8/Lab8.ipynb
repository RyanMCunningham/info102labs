{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8\n",
    "\n",
    "## Crawling Wikipedia\n",
    "Below, you'll find a Python program. Feel free to run it. The function `find_links` extracts URLs from a web page. The functions `bfs` and `dfs` perform breadth-first and depth-first searches of the links on a web page. Change the parameter `start_url` (it's waaaay down at the bottom of the program) to the Wikipedia entry for your favorite topic. Pick something you know a lot about. Run the program. It should print out the entries visited along the way. Try different values for `max_visits` and `start_url`. Also, try replacing bfs with dfs. Note that algorithm randomly chooses which links to visit, so you can run the program with the same inputs and see different outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initialization stuff. Don't worry about what it does\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "import re, urllib, random\n",
    "p=re.compile(\"\\/wiki\\/([^:]+)\")\n",
    "ignore=set([\"Wikipedia\",\"Help\",\"Portal\",\"Category\",\"Main_Page\",\"File\",\"Talk\",\"Template\",\"Template_talk\",\"Special\"])\n",
    "\n",
    "'''\n",
    "Function to extract all of the URLs from a Wikipedia page\n",
    "'''\n",
    "def get_links(page):\n",
    "    page=\"https://en.wikipedia.org/wiki/%s\"%page\n",
    "    r = urllib.request.urlopen(page).read()\n",
    "    soup = BeautifulSoup(r,'html')\n",
    "\n",
    "    links=[]\n",
    "    for tag in soup.find_all('a'):\n",
    "        s=tag.get('href')\n",
    "        if s:\n",
    "            m=p.match(s)\n",
    "            if m:\n",
    "                newurl=m.group(1)\n",
    "                if newurl not in ignore:\n",
    "                    #newurl=urllib.quote(newurl.encode('utf8'), ':/')\n",
    "                    links.append(newurl)\n",
    "    random.shuffle(links)\n",
    "    return links\n",
    "\n",
    "'''\n",
    "A depth first search function that starts at url and visits max_visits nodes\n",
    "'''\n",
    "def dfs(url,max_visits):\n",
    "    visited=[]\n",
    "    stack=[]\n",
    "    stack.append(url)\n",
    "    while stack:\n",
    "        if len(visited)>=max_visits:\n",
    "            return visited\n",
    "        current=stack.pop()\n",
    "        if current not in visited:\n",
    "            for neighbor in get_links(current):\n",
    "                stack.append(neighbor)\n",
    "            visited.append(current)\n",
    "\n",
    "\n",
    "'''\n",
    "A breadth first search function that starts at url and visits max_visits nodes\n",
    "'''\n",
    "def bfs(url,max_visits):\n",
    "    visited=[]\n",
    "    stack=[]\n",
    "    stack.append(url)\n",
    "    while stack:\n",
    "        if len(visited)>=max_visits:\n",
    "            return visited\n",
    "        current=stack.pop(0)\n",
    "        if current not in visited:\n",
    "            for neighbor in get_links(current):\n",
    "                stack.append(neighbor)\n",
    "            visited.append(current)\n",
    "            \n",
    "'''\n",
    "Main program for you to play with\n",
    "'''\n",
    "start_url=\"Alan_Turing\"     # the starting url for our crawl\n",
    "max_visits=50               # the max number of nodes to visit\n",
    "for i,link in enumerate(bfs(start_url,max_visits)):\n",
    "    print(i,link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Trie\n",
    "In this section, we will look at another application for graphs we didn’t discuss in class. Feel free to run the program below. You can change the variable sentence to anything you like. Try running the program a few times with different sentences. The program produces directed graphs, but they look a little different than what we saw in class. Thick lines are used instead of arrows to indicate the direction of the edge. If the graph visualization is difficult to see, note that the program also saves the image as a file named `trie.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "END=\"_end\" # special string representing the end of a word\n",
    "\n",
    "'''\n",
    "adds a word to our trie\n",
    "'''\n",
    "def add_word(root,word):\n",
    "    current=root\n",
    "    for c in word:\n",
    "        if c in current:\n",
    "            current=current[c]\n",
    "        else:\n",
    "            current[c]={}\n",
    "            current=current[c]\n",
    "    if END in current:\n",
    "        current[END]+=1\n",
    "    else:\n",
    "        current[END]=1\n",
    "\n",
    "\n",
    "def draw_graph(root):\n",
    "    import networkx as nx\n",
    "    from networkx.drawing.nx_agraph import write_dot, graphviz_layout\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    G=nx.DiGraph()\n",
    "    node_names={\"\":1}\n",
    "    G.add_node(1)\n",
    "    dfs(root,\"\",G,node_names)\n",
    "    plt.rc('figure', figsize=(20,20))\n",
    "    pos = nx.shell_layout(G)\n",
    "    nx.draw(G,pos=pos,node_color=\"lightsteelblue\")\n",
    "    nx.draw_networkx_labels(G,pos)\n",
    "    nx.draw_networkx_edge_labels(G,pos,edge_labels=nx.get_edge_attributes(G,'label'))\n",
    "    plt.savefig(\"trie.png\", format=\"PNG\")\n",
    "    \n",
    "def dfs(node,s,G,node_names):\n",
    "    for c in node:\n",
    "        if c != END:\n",
    "            sc=s+c\n",
    "            if sc not in node_names:\n",
    "                node_names[sc]=len(node_names)+1\n",
    "                G.add_node(node_names[sc])\n",
    "            G.add_edge(node_names[s],node_names[sc],label=c)\n",
    "            dfs(node[c],sc,G,node_names)\n",
    "\n",
    "root={}\n",
    "sentence=\"she sells sea shells down by the sea shore\"\n",
    "for word in sentence.split():\n",
    "    add_word(root,word)\n",
    "\n",
    "draw_graph(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trie Trie Again\n",
    "In this section, we’ll look at tries again. The program here is almost exactly the same as in the previous section. Instead of visualizing the trie, we’re going to examine the `find_word` function. Experiment with different values for sentence and query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "END=\"_end\" # special string representing the end of a word\n",
    "\n",
    "'''\n",
    "adds a word to our trie\n",
    "'''\n",
    "def add_word(root,word):\n",
    "    current=root\n",
    "    for c in word:\n",
    "        if c in current:\n",
    "            current=current[c]\n",
    "        else:\n",
    "            current[c]={}\n",
    "            current=current[c]\n",
    "    if END in current:\n",
    "        current[END]+=1\n",
    "    else:\n",
    "        current[END]=1\n",
    "        \n",
    "'''\n",
    "finds a word in our trie\n",
    "'''\n",
    "def find_word(root,word):\n",
    "    current=root\n",
    "    for c in word:\n",
    "        if c in current:\n",
    "            current=current[c]\n",
    "        else:\n",
    "            return 0\n",
    "    if END in current:\n",
    "        return current[END]\n",
    "    else:\n",
    "        return 0   \n",
    "\n",
    "root={}\n",
    "sentence=\"she sells sea shells down by the sea shore\"\n",
    "query=\"sea\"\n",
    "\n",
    "for word in sentence.split():\n",
    "    add_word(root,word)\n",
    "\n",
    "print(find_word(root,query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trie Hard\n",
    "Once again, we are going to look at tries. Instead of a sentence you supply, this program will load all of the words in the classic book Frankenstein. The *entire contents* of the novel are stored in `frankenstein.txt`. Again, you should try examining different values for `query`. This is the word we're searching for in the book. The program will tell you how long it took to read and process the book, how long it took to search the book for the word, and how many times that word appeared in the book. I hope you're impressed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "END=\"_end\" # special string representing the end of a word\n",
    "\n",
    "# adds a word to our trie\n",
    "def add_word(root,word):\n",
    "    current=root\n",
    "    for c in word:\n",
    "        if c in current:\n",
    "            current=current[c]\n",
    "        else:\n",
    "            current[c]={}\n",
    "            current=current[c]\n",
    "    if END in current:\n",
    "        current[END]+=1\n",
    "    else:\n",
    "        current[END]=1\n",
    "        \n",
    "# finds a word in our trie\n",
    "def find_word(root,word):\n",
    "    current=root\n",
    "    for c in word:\n",
    "        if c in current:\n",
    "            current=current[c]\n",
    "        else:\n",
    "            return 0\n",
    "    if END in current:\n",
    "        return current[END]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def read_book():\n",
    "    import re\n",
    "    f=open(\"frankenstein.txt\",'r')\n",
    "    text=f.read()\n",
    "    f.close()\n",
    "    words= re.split(\"[^a-zA-Z0-9]\",text)\n",
    "    return [w.lower() for w in words if len(w)>2 ]\n",
    "\n",
    "start=timer()\n",
    "words=read_book()\n",
    "end=timer()\n",
    "time=end-start\n",
    "print(\"Reading the book took %s seconds.\" % time)\n",
    "\n",
    "root={}\n",
    "for word in words:\n",
    "    add_word(root,word)\n",
    "\n",
    "query=\"monster\"\n",
    "start=timer()\n",
    "result=find_word(root,query)\n",
    "end=timer()\n",
    "time=end-start\n",
    "print(\"Searching the book took %s seconds.\" % time)\n",
    "print(\"The result of the search was: %d\" % result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Questions\n",
    "\n",
    "1. In the crawling program what role does `max_visits` play? Why do we need this parameter?\n",
    "2. In the crawling program, how does the output from `dfs` differ from `bfs`? How would you describe what you see to a friend who hasn’t taken this class? Is there an intuitive difference between the way DFS and BFS explore topics?\n",
    "3. Are the searches in our crawling program over a tree? In other words, is Wikipedia a tree? Why or why not?\n",
    "4. Are the graphs produced in \"First Trie\" a tree? Why or why not?\n",
    "5. What information is being captured in the graph in \"First Trie\"? Why might it be useful?\n",
    "6. What would a depth first search of the graph in \"First Trie produce?\n",
    "7. What is the `find_word` function in \"Trie Trie Again\" doing? What value does it return?\n",
    "8. How long does it take to read the book in \"Trie Hard\"? How long does it take to search the book? Do these results surprise or impress you?\n",
    "9. In \"Trie Hard\", does the length of the query string impact the amount of time required to search the book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
